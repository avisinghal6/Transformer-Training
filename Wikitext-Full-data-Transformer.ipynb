{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:25:08.186711Z","iopub.status.busy":"2022-12-01T19:25:08.186290Z","iopub.status.idle":"2022-12-01T19:25:10.987431Z","shell.execute_reply":"2022-12-01T19:25:10.985804Z","shell.execute_reply.started":"2022-12-01T19:25:08.186636Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import random\n","\n","#replace with pytorch lightning\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","\n","from sklearn.preprocessing import MinMaxScaler    \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","import string"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:25:10.990584Z","iopub.status.busy":"2022-12-01T19:25:10.989643Z","iopub.status.idle":"2022-12-01T19:26:07.381861Z","shell.execute_reply":"2022-12-01T19:26:07.380833Z","shell.execute_reply.started":"2022-12-01T19:25:10.990538Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"wikitext\",\"wikitext-103-raw-v1\", split=\"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:08.342723Z","iopub.status.busy":"2022-12-01T19:31:08.342149Z","iopub.status.idle":"2022-12-01T19:31:08.348334Z","shell.execute_reply":"2022-12-01T19:31:08.347278Z","shell.execute_reply.started":"2022-12-01T19:31:08.342690Z"},"trusted":true},"outputs":[],"source":["# dataset=dataset.select(list(np.arange(0,600000)))\n","print(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:09.638479Z","iopub.status.busy":"2022-12-01T19:31:09.638007Z","iopub.status.idle":"2022-12-01T19:31:09.706304Z","shell.execute_reply":"2022-12-01T19:31:09.705112Z","shell.execute_reply.started":"2022-12-01T19:31:09.638438Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(device)\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:50.127549Z","iopub.status.busy":"2022-12-01T19:31:50.126958Z","iopub.status.idle":"2022-12-01T19:31:50.133531Z","shell.execute_reply":"2022-12-01T19:31:50.132571Z","shell.execute_reply.started":"2022-12-01T19:31:50.127515Z"},"trusted":true},"outputs":[],"source":["def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n","    \"\"\"\n","    Mask the upper half of the dot product matrix in self attention.\n","    This prevents flow of information from future tokens to current token.\n","    1's in the lower triangle, counting from the lower right corner.\n","    \"\"\"\n","    i=torch.range(1,n_dest)[:,None]\n","    j=torch.range(1,n_src)\n","    m = i >= j - n_src + n_dest\n","    mask=m.bool()\n","    return ~mask\n","#     mask=torch.reshape(mask, [1, n_dest, n_src])\n","#     mult=[batch_size,1,1]\n","#     return torch.tile(mask,mult);"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:50.620176Z","iopub.status.busy":"2022-12-01T19:31:50.619512Z","iopub.status.idle":"2022-12-01T19:31:50.633262Z","shell.execute_reply":"2022-12-01T19:31:50.632297Z","shell.execute_reply.started":"2022-12-01T19:31:50.620140Z"},"trusted":true},"outputs":[],"source":["causal_attention_mask(2,5,5,torch.bool)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:50.882651Z","iopub.status.busy":"2022-12-01T19:31:50.881705Z","iopub.status.idle":"2022-12-01T19:31:50.887879Z","shell.execute_reply":"2022-12-01T19:31:50.886905Z","shell.execute_reply.started":"2022-12-01T19:31:50.882611Z"},"trusted":true},"outputs":[],"source":["def padding_mask(input):\n","    # Create mask which marks the zero padding values in the input by a 1\n","#     print(input)\n","#     input=torch.tensor(input['train']['input_ids'])\n","    mask=torch.eq(input, torch.zeros_like(input))\n","\n"," \n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:51.356729Z","iopub.status.busy":"2022-12-01T19:31:51.356159Z","iopub.status.idle":"2022-12-01T19:31:51.368590Z","shell.execute_reply":"2022-12-01T19:31:51.367193Z","shell.execute_reply.started":"2022-12-01T19:31:51.356688Z"},"trusted":true},"outputs":[],"source":["padding_mask(torch.tensor([[1,2,3,0,0,0],[2,0,0,0,0,0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:51.693339Z","iopub.status.busy":"2022-12-01T19:31:51.692798Z","iopub.status.idle":"2022-12-01T19:31:51.702822Z","shell.execute_reply":"2022-12-01T19:31:51.701733Z","shell.execute_reply.started":"2022-12-01T19:31:51.693298Z"},"trusted":true},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads,batch_first,rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim,num_heads,batch_first=batch_first)\n","\n","    def forward(self, inputs,pad_mask):\n","        input_shape = inputs.size()\n","        batch_size = input_shape[0]\n","        seq_len = input_shape[1]\n","#         pad_mask=padding_mask(inputs)\n","        pad_mask.to(device)\n","        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, torch.bool).to(device)\n","        attention_output,a = self.attention(inputs, inputs,inputs, key_padding_mask=pad_mask, attn_mask=causal_mask,need_weights=True,average_attn_weights=False)\n","        return attention_output,a"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:52.320424Z","iopub.status.busy":"2022-12-01T19:31:52.320071Z","iopub.status.idle":"2022-12-01T19:31:52.327603Z","shell.execute_reply":"2022-12-01T19:31:52.326716Z","shell.execute_reply.started":"2022-12-01T19:31:52.320394Z"},"trusted":true},"outputs":[],"source":["class TokenAndPositionEmbedding(nn.Module):\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = nn.Embedding(vocab_size, embed_dim,max_norm=1)\n","        self.pos_emb = nn.Embedding(maxlen,embed_dim)\n","\n","    def forward(self, x):\n","        maxlen = x.size()[-1]\n","        pad_mask=padding_mask(x)\n","        positions = torch.range(start=0, end=maxlen-1, step=1,dtype=torch.int32).to(device)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return (x + positions),pad_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:52.702368Z","iopub.status.busy":"2022-12-01T19:31:52.701995Z","iopub.status.idle":"2022-12-01T19:31:52.709941Z","shell.execute_reply":"2022-12-01T19:31:52.708859Z","shell.execute_reply.started":"2022-12-01T19:31:52.702339Z"},"trusted":true},"outputs":[],"source":["vocab_size =50257 #28996  # Only consider the top 20k words\n","maxlen = 80  # Max sequence size\n","embed_dim = 256  # Embedding size for each token\n","num_heads = 8  # Number of attention heads\n","feed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n","        self.transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim,True)\n","        self.outputs= nn.LazyLinear(vocab_size)\n","        \n","    def forward(self, x):\n","        x,pad_mask = self.embedding_layer(x)\n","#         print(x,\"maximum=\",torch.max(x))\n","        x,a = self.transformer_block(x,pad_mask)\n","#         print(x)\n","        x = self.outputs(x)\n","        \n","        return x,a\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:31:53.987136Z","iopub.status.busy":"2022-12-01T19:31:53.986766Z","iopub.status.idle":"2022-12-01T19:32:14.487533Z","shell.execute_reply":"2022-12-01T19:32:14.485915Z","shell.execute_reply.started":"2022-12-01T19:31:53.987103Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","import re\n","# directories = [\n","#     \"/kaggle/input/aclimdb-v1/aclImdb/train/pos\",\n","#     \"/kaggle/input/aclimdb-v1/aclImdb/train/neg\",\n","#     \"/kaggle/input/aclimdb-v1/aclImdb/test/pos\",\n","#     \"/kaggle/input/aclimdb-v1/aclImdb/test/neg\",\n","# ]\n","\n","# from datasets import load_dataset\n","# filenames = []\n","# for dir in directories:\n","#     for f in os.listdir(dir):\n","#         filenames.append(os.path.join(dir, f))\n","\n","# dataset = load_dataset(\"text\", data_files=filenames)\n","\n","def processing(s):\n","  s['text']=s['text'].lower()\n","  s['text']=re.sub(\"<br />\", \" \", s['text'])\n","  s['text']=re.sub(f\"([{string.punctuation}])\", r\" \\1\", s['text'])\n","  return s\n","\n","dataset=dataset.map(processing)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = dataset.filter(lambda example: example['text']!=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T23:58:27.136078Z","iopub.status.busy":"2022-11-30T23:58:27.131258Z","iopub.status.idle":"2022-11-30T23:58:27.826627Z","shell.execute_reply":"2022-11-30T23:58:27.825636Z","shell.execute_reply.started":"2022-11-30T23:58:27.136020Z"},"trusted":true},"outputs":[],"source":["# from transformers import AutoTokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","from transformers import GPT2Tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T23:58:31.642762Z","iopub.status.busy":"2022-11-30T23:58:31.642373Z","iopub.status.idle":"2022-12-01T00:05:47.054060Z","shell.execute_reply":"2022-12-01T00:05:47.053017Z","shell.execute_reply.started":"2022-11-30T23:58:31.642728Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.map(lambda dataset: tokenizer(dataset[\"text\"],truncation=True, max_length=maxlen))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:13:22.109559Z","iopub.status.busy":"2022-12-01T00:13:22.108965Z","iopub.status.idle":"2022-12-01T00:14:28.650608Z","shell.execute_reply":"2022-12-01T00:14:28.649721Z","shell.execute_reply.started":"2022-12-01T00:13:22.109521Z"},"trusted":true},"outputs":[],"source":["def padding(s):\n","    if len(s['input_ids'])<maxlen :\n","        s['input_ids']=s['input_ids']+[0]*(maxlen-len(s['input_ids']))\n","    return s\n","                                           \n","dataset=dataset.map(padding)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:18:08.129410Z","iopub.status.busy":"2022-12-01T00:18:08.129032Z","iopub.status.idle":"2022-12-01T00:19:03.399719Z","shell.execute_reply":"2022-12-01T00:19:03.398723Z","shell.execute_reply.started":"2022-12-01T00:18:08.129372Z"},"trusted":true},"outputs":[],"source":["# count=0\n","# for i in dataset:\n","#     if len(i['input_ids'])!=50:\n","#         print(len(i['input_ids']))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:34:44.236483Z","iopub.status.busy":"2022-12-01T19:34:44.235828Z","iopub.status.idle":"2022-12-01T19:34:45.908447Z","shell.execute_reply":"2022-12-01T19:34:45.907551Z","shell.execute_reply.started":"2022-12-01T19:34:44.236446Z"},"trusted":true},"outputs":[],"source":["model=Model()\n","model.load_state_dict(torch.load(\"/kaggle/input/saved-weights/transformer_weights_10.pth\")) \n","model.to(device)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-11-23T19:37:34.977741Z","iopub.status.busy":"2022-11-23T19:37:34.977324Z","iopub.status.idle":"2022-11-23T19:37:35.372676Z","shell.execute_reply":"2022-11-23T19:37:35.371685Z","shell.execute_reply.started":"2022-11-23T19:37:34.977705Z"}},"source":["<!-- # model= Model()\n","# model.to(device) -->"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T19:32:21.406306Z","iopub.status.busy":"2022-12-01T19:32:21.405945Z","iopub.status.idle":"2022-12-01T19:32:21.431403Z","shell.execute_reply":"2022-12-01T19:32:21.429874Z","shell.execute_reply.started":"2022-12-01T19:32:21.406277Z"},"trusted":true},"outputs":[],"source":["class TextGenerator(nn.Module):\n","    \"\"\"A callback to generate text from a trained model.\n","    1. Feed some starting prompt to the model\n","    2. Predict probabilities for the next token\n","    3. Sample the next token and add it to the next input\n","\n","    Arguments:\n","        max_tokens: Integer, the number of tokens to be generated after prompt.\n","        start_tokens: List of integers, the token indices for the starting prompt.\n","        index_to_word: List of strings, obtained from the TextVectorization layer.\n","        top_k: Integer, sample from the `top_k` token predictions.\n","        print_every: Integer, print after this many epochs.\n","    \"\"\"\n","\n","    def __init__(\n","        self, max_tokens, start_tokens, top_k=10, print_every=1\n","    ):\n","        self.max_tokens = max_tokens\n","        self.start_tokens = start_tokens\n","#         self.index_to_word = index_to_word\n","        self.print_every = print_every\n","        self.k = top_k\n","\n","    def sample_from(self, logits):\n","        logits, indices = torch.topk(logits, k=self.k, sorted=True)\n","        logits=logits.cpu()\n","        indices=indices.cpu()\n","        indices = np.asarray(indices).astype(\"int32\")\n","       \n","        softmax=nn.Softmax(dim=0)\n","        preds = softmax(logits)\n","        preds = np.asarray(preds).astype(\"float32\")\n","#         return np.random.choice(indices, p=preds) THIS IS THE CORRECT CODE, BUT HAD TO COMMENT IT AS\n","#.        PROBABILITIES HAVE NAN AND I HAD TO VERIFY PIPELINE, BELOW LINE WILL BE REMOVED ONCE NAN ISSUE \n","#.        IS RESOLVED\n","        return np.random.choice(indices, p=preds)\n","#         return np.random.choice(5, 1, p=[0.1, 0, 0.3, 0.6, 0])\n","\n","    def detokenize(self, number):\n","        return tokenizer.decode(number)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        start_tokens = [_ for _ in self.start_tokens]\n","        if (epoch + 1) % self.print_every != 0:\n","            return\n","        num_tokens_generated = 0\n","        tokens_generated = []\n","        attention_scores=[]\n","        while num_tokens_generated <= self.max_tokens:\n","            pad_len = maxlen - len(start_tokens)\n","            sample_index = len(start_tokens) - 1\n","            if pad_len < 0:\n","                data = start_tokens[:maxlen]\n","                sample_index = maxlen - 1\n","            elif pad_len > 0:\n","                data = start_tokens + [0] * pad_len\n","            else:\n","                data = start_tokens\n","                \n","            data = torch.Tensor(np.array([data])).type(torch.int32).to(device)\n","            \n","            y,attention_scores = model(data)\n","            sample_token = self.sample_from(y[0][sample_index])\n","            tokens_generated.append(sample_token)\n","            start_tokens.append(sample_token)\n","            num_tokens_generated = len(tokens_generated)\n","        txt = \" \".join(\n","            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n","        )\n","        print(f\"generated text:\\n{txt}\\n\")\n","        return attention_scores[0]\n","\n","# Tokenize starting prompt\n","# word_to_index = {}\n","# for index, word in enumerate(vocab):\n","#     word_to_index[word] = index\n","\n","start_prompt = \"this is movie is better than the rest, it is rated higher and is funny\"\n","start_tokens=tokenizer(start_prompt)['input_ids']\n","# start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n","num_tokens_generated = 40\n","# text_gen_callback = TextGenerator(num_tokens_generated, start_tokens, vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:21:29.835324Z","iopub.status.busy":"2022-12-01T00:21:29.834961Z","iopub.status.idle":"2022-12-01T00:21:46.934274Z","shell.execute_reply":"2022-12-01T00:21:46.933283Z","shell.execute_reply.started":"2022-12-01T00:21:29.835292Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset\n","train_dataset= Dataset.from_dict({\"id\": dataset['input_ids']})\n","train_dataset = train_dataset.with_format(\"torch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:43:23.983338Z","iopub.status.busy":"2022-12-01T00:43:23.982942Z","iopub.status.idle":"2022-12-01T00:43:27.214308Z","shell.execute_reply":"2022-12-01T00:43:27.213026Z","shell.execute_reply.started":"2022-12-01T00:43:23.983303Z"},"trusted":true},"outputs":[],"source":["# print(train_dataset['id'][3])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:21:53.310589Z","iopub.status.busy":"2022-12-01T00:21:53.310217Z","iopub.status.idle":"2022-12-01T00:21:54.288675Z","shell.execute_reply":"2022-12-01T00:21:54.287623Z","shell.execute_reply.started":"2022-12-01T00:21:53.310557Z"},"trusted":true},"outputs":[],"source":["count=0\n","TEST=[]\n","train_loader=DataLoader(train_dataset,batch_size=50,shuffle=True)\n","for i in train_loader:\n","    TEST.append(random.choice(i['id']))\n","    if count>100:\n","        break\n","    count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:21:56.528584Z","iopub.status.busy":"2022-12-01T00:21:56.527664Z","iopub.status.idle":"2022-12-01T00:21:56.534109Z","shell.execute_reply":"2022-12-01T00:21:56.532904Z","shell.execute_reply.started":"2022-12-01T00:21:56.528532Z"},"trusted":true},"outputs":[],"source":["TEST=torch.stack(TEST,0) \n","# print(TEST[:,:])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mkdir /kaggle/working/saved_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T00:21:58.634081Z","iopub.status.busy":"2022-12-01T00:21:58.632701Z","iopub.status.idle":"2022-12-01T00:34:20.930929Z","shell.execute_reply":"2022-12-01T00:34:20.929419Z","shell.execute_reply.started":"2022-12-01T00:21:58.634029Z"},"trusted":true},"outputs":[],"source":["train_loader=DataLoader(train_dataset,batch_size=50,shuffle=True)\n","optim=torch.optim.AdamW(model.parameters(),lr=1e-4)\n","loss_fn=torch.nn.CrossEntropyLoss()\n","count=0\n","loss_stats = {\n","    'test': [],\n","}\n","for epoch in tqdm(range(15)):\n","    for batch in tqdm(train_loader):\n","        optim.zero_grad()\n","#         print(batch['id'][:,:-1])\n","        input_ids=batch['id'][:,:-1].to(device)\n","#         print(input_ids.shape())\n","        labels=batch['id'][:,1:].to(device)\n","        outputs,attention_scores=model.forward(input_ids)\n","        labels=nn.functional.one_hot(labels,num_classes=vocab_size).type(torch.float)\n","        loss=loss_fn(outputs,labels)\n","        loss.backward()\n","        optim.step()\n","    \n","    with torch.no_grad():\n","        TextGenerator(40, start_tokens).on_epoch_end(epoch);\n","        test_input=TEST[:,:-1].to(device)\n","        test_output=TEST[:,1:].to(device)\n","        outputs,attention_scores=model.forward(test_input)\n","        labels=nn.functional.one_hot(test_output,num_classes=vocab_size).type(torch.float)\n","        loss=loss_fn(outputs,labels).cpu().item()\n","        loss_stats['test'].append(loss)\n","    if epoch%5==0:\n","        torch.save(model.state_dict(),f\"/kaggle/working/saved_models/transformer_weights_{10+epoch}.pth\")\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T20:06:09.793293Z","iopub.status.busy":"2022-11-23T20:06:09.792378Z","iopub.status.idle":"2022-11-23T20:06:10.077278Z","shell.execute_reply":"2022-11-23T20:06:10.076327Z","shell.execute_reply.started":"2022-11-23T20:06:09.793257Z"},"trusted":true},"outputs":[],"source":["test_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n","# Plot the dataframes\n","fig,axes = plt.subplots(nrows=1, ncols=1, figsize=(20,7))\n","sns.lineplot(data=test_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes).set_title('TestLoss')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !mkdir /kaggle/working/saved_models/\n","torch.save(model.state_dict(),\"/kaggle/working/saved_models/transformer_weights.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:20.574748Z","iopub.status.busy":"2022-11-30T18:42:20.574396Z","iopub.status.idle":"2022-11-30T18:42:20.615225Z","shell.execute_reply":"2022-11-30T18:42:20.614040Z","shell.execute_reply.started":"2022-11-30T18:42:20.574720Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    score=TextGenerator(20, start_tokens).on_epoch_end(1);\n","score=score.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T19:00:08.422148Z","iopub.status.busy":"2022-11-30T19:00:08.421194Z","iopub.status.idle":"2022-11-30T19:00:15.288069Z","shell.execute_reply":"2022-11-30T19:00:15.286149Z","shell.execute_reply.started":"2022-11-30T19:00:08.422101Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[0],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:32.972808Z","iopub.status.busy":"2022-11-30T18:42:32.971631Z","iopub.status.idle":"2022-11-30T18:42:36.841564Z","shell.execute_reply":"2022-11-30T18:42:36.840480Z","shell.execute_reply.started":"2022-11-30T18:42:32.972771Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[1],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T19:04:14.069774Z","iopub.status.busy":"2022-11-30T19:04:14.069420Z","iopub.status.idle":"2022-11-30T19:04:21.062013Z","shell.execute_reply":"2022-11-30T19:04:21.060883Z","shell.execute_reply.started":"2022-11-30T19:04:14.069745Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[2],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');\n","plt.savefig(\"head3.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:40.894415Z","iopub.status.busy":"2022-11-30T18:42:40.894044Z","iopub.status.idle":"2022-11-30T18:42:44.965203Z","shell.execute_reply":"2022-11-30T18:42:44.964151Z","shell.execute_reply.started":"2022-11-30T18:42:40.894382Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[3],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:44.967372Z","iopub.status.busy":"2022-11-30T18:42:44.967018Z","iopub.status.idle":"2022-11-30T18:42:49.072015Z","shell.execute_reply":"2022-11-30T18:42:49.071191Z","shell.execute_reply.started":"2022-11-30T18:42:44.967340Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[4],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T19:01:37.833162Z","iopub.status.busy":"2022-11-30T19:01:37.832746Z","iopub.status.idle":"2022-11-30T19:01:44.915092Z","shell.execute_reply":"2022-11-30T19:01:44.914167Z","shell.execute_reply.started":"2022-11-30T19:01:37.833119Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[5],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');\n","plt.savefig(\"head6.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:53.065447Z","iopub.status.busy":"2022-11-30T18:42:53.065096Z","iopub.status.idle":"2022-11-30T18:42:56.869721Z","shell.execute_reply":"2022-11-30T18:42:56.868752Z","shell.execute_reply.started":"2022-11-30T18:42:53.065414Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[6],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-30T18:42:56.871713Z","iopub.status.busy":"2022-11-30T18:42:56.870940Z","iopub.status.idle":"2022-11-30T18:43:00.637683Z","shell.execute_reply":"2022-11-30T18:43:00.636597Z","shell.execute_reply.started":"2022-11-30T18:42:56.871675Z"},"trusted":true},"outputs":[],"source":["dfx = pd.DataFrame(list(np.arange(maxlen)), columns =['Keys'] );\n","dfy2=pd.DataFrame(score[7],columns=list(np.arange(maxlen)));\n","plt.figure(figsize=(100.0,100.0));\n","plt.title(\"Attention scores\");\n","plt.xlabel('Keys',size=maxlen);\n","plt.ylabel('Queries',size=maxlen);\n","plt.plot();\n","sns.heatmap(dfy2,fmt=\".3f\",annot=True,linewidths=2,square=True,cmap='twilight');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"envConda","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]"},"vscode":{"interpreter":{"hash":"d79b2744bc6e1882128d7c84b82da7af0e62d7586ee01776c094807ca1ed93db"}}},"nbformat":4,"nbformat_minor":4}
